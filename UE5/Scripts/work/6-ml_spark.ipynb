{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import avg, col, concat,count, desc, explode, lit, min, max, split, stddev, udf\nfrom pyspark.sql.types import IntegerType\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import CountVectorizer, IDF, Normalizer, PCA, RegexTokenizer, StandardScaler, StopWordsRemover, StringIndexer, VectorAssembler\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e9e7f3b6-da48-43bd-8c6f-7c6c25ce18f6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e923888f-fe6a-43e0-b4a8-feae3d985eab","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stack_overflow_data = \"/FileStore/tables/stack.json\"\ndf2 = spark.read.json(stack_overflow_data)\ndf2.persist()\n\n\nregexTokenizer = RegexTokenizer(inputCol=\"Body\", outputCol=\"words\", pattern=\"\\\\W\")\ncv = CountVectorizer(inputCol=\"words\", outputCol=\"TF\", vocabSize=10000)\nidf = IDF(inputCol=\"TF\", outputCol=\"features\") # Inverse document frequency \nindexer = StringIndexer(inputCol=\"oneTag\", outputCol=\"label\")\n\nlr = LogisticRegression(maxIter=10, regParam=0.0, elasticNetParam=0)\n\npipeline = Pipeline(stages=[regexTokenizer, cv, idf, indexer, lr])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c14ccff6-d390-4817-9e5a-f16be3a0c4f4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["plrModel = pipeline.fit(df2)\n\ndf3 = plrModel.transform(df2)\ndf3.head()\n\ndf3.filter(df3.label == df3.prediction).count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"673f0804-fa9c-4617-849b-eefe37f4f971","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[6]: 68955","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[6]: 68955"]}}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.0","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"6-ml_spark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2967774331460148}},"nbformat":4,"nbformat_minor":0}
